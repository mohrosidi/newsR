url$scheme <- "https"
url$query <- query_params
## Data parsed
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = api_key))
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
tidy_data <- parsed %>% pluck(3) %>% tibble::as_tibble()
return(tidy_data)
}
news_headlines(api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(keywords = "Surabaya", api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
query_params <- list(category  = NULL,
sources   = NULL,
country   = "us",
q         = "Trump",
pageSize  = 100,
page      = 1)
url <- httr::parse_url(url = "https://newsapi.org/v2/top-headlines")
url$scheme <- "https"
url$query <- query_params
View(url)
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = "dec7dc7eec124dbfb2adb9034c71b0bd"))
View(resp)
resp[["headers"]]
resp[["content"]]
resp[["url"]]
resp[["cookies"]]
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
parsed
news_headlines <- function(keywords = NULL,
category = NULL,
country = NULL,
sources = NULL,
page = 1,
pageSize = 100,
api_key = Sys.getenv("NEWS_API_KEY")){
# error and warning handling ------
## if any arguments NULL
if(all(map_lgl(list(keywords, category, country, sources), is.null))){
stop(paste("Please provide at least keywords, category, country, and source"))
}
## Check if combination sources, country or category allowed
if (!is.null(sources) & (!is.null(country) | !is.null(category))){
stop(paste0("'sources' cannot be used together with ",
"'country' and/or 'category'."))
}
## Check keywords
if(!is.null(keywords)){
if(length(keywords) > 1){
stop("You can only specify one keywords string.")
}
}
## Check category
if(!is.null(category)){
if(length(category) > 1){
stop("You cannot specify more than one category.")
}
if(!category %in% c("business", "entertainment", "general",
"health", "science", "sports", "technology")){
stop(paste(category, "is not valid. Please specify it using business, entertainment, general, health, science, sports, or technology"))
}
}
## Check country
if(!is.null(country)){
if(length(country)>1){
stop("You cannot specify more than one country")
}
if(!country %in% c("ae", "ar", "at", "au", "be", "bg", "br", "ca",
"ch", "cn", "co", "cu", "cz", "de", "eg", "fr",
"gb", "gr", "hk", "hu", "id", "ie", "il", "in",
"it", "jp", "kr", "lt", "lv", "ma", "mx", "my",
"ng", "nl", "no", "nz", "ph", "pl", "pt", "ro",
"rs", "ru", "sa", "se", "sg", "si", "sk", "th",
"tr", "tw", "ua", "us", "ve", "za")){
stop(paste(country, 'is not valid. Please specify it using "ae", "ar", "at", "au", "be", "bg", "br", "ca"',
'"ch", "cn", "co", "cu", "cz", "de", "eg", "fr"',
'"gb", "gr", "hk", "hu", "id", "ie", "il", "in"',
'"it", "jp", "kr", "lt", "lv", "ma", "mx", "my"',
'"ng", "nl", "no", "nz", "ph", "pl", "pt", "ro"',
'"rs", "ru", "sa", "se", "sg", "si", "sk", "th"',
'"tr", "tw", "ua", "us", "ve", or "za".',
"See : https://newsapi.org/sources"))
}
}
## Check sources
source_vec <- news_sources(api_key = api_key) %>%
select(id) %>%
pull()
if(!is.null(sources)){
if(length(sources)>1){
stop("You cannot specify more than one country")
}
if(!source %in% source_vec){
stop(paste0(source, "is not valid. Check news_sources(<YOUR API KEY>)"))
}
}
## Check page
if(!is.numeric(page)) {
stop("Page should be a number.")
}
## Check pageSize
if(!is.numeric(pageSize)) {
stop("You need to insert numeric values for the number of texts per page.")
}
else if(pageSize > 100) {
stop("Page size cannot not exceed 100 articles per page.")
}
## Check api_key
if (nchar(api_key) == 0){
stop(paste("You did not correctly specify your API key neither as global",
"variable nor with the function call. See documentation for",
"further info."))
}
# Access NEWS API ----
## Query
query_params <- list(category  = category,
sources   = sources,
country   = country,
q         = keywords,
pageSize  = pageSize,
page      = page)
url <- httr::parse_url(url = "https://newsapi.org/v2/top-headlines")
url$scheme <- "https"
url$query <- query_params
## Data parsed
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = api_key))
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
tidy_data <- parsed %>% pluck(3) %>% tibble::as_tibble()
return(tidy_data)
}
news_headlines(category = "sports", keywords = "Ronaldo", api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(category = "sports", keywords = "Ronaldo", page = 2, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(category = "sports", keywords = "Ronaldo", page = 2, pageSize = 50, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(keywords = "Trump", country = "us", page = 2, pageSize = 50, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(keywords = "Trump", country = "us", api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
newsanchor::get_headlines(query = "trump", api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
View(parsed)
parsed[["totalResults"]]
View(resp)
a <- newsanchor::get_headlines(query = "trump", api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
View(a)
a[["metadata"]]
View(parsed)
resp %>% pluck(2)
news_headlines <- function(keywords = NULL,
category = NULL,
country = NULL,
sources = NULL,
page = 1,
pageSize = 100,
get_all = FALSE,
api_key = Sys.getenv("NEWS_API_KEY")){
# error and warning handling ------
## if any arguments NULL
if(all(map_lgl(list(keywords, category, country, sources), is.null))){
stop(paste("Please provide at least keywords, category, country, and source"))
}
## Check if combination sources, country or category allowed
if (!is.null(sources) & (!is.null(country) | !is.null(category))){
stop(paste0("'sources' cannot be used together with ",
"'country' and/or 'category'."))
}
## Check keywords
if(!is.null(keywords)){
if(length(keywords) > 1){
stop("You can only specify one keywords string.")
}
}
## Check category
if(!is.null(category)){
if(length(category) > 1){
stop("You cannot specify more than one category.")
}
if(!category %in% c("business", "entertainment", "general",
"health", "science", "sports", "technology")){
stop(paste(category, "is not valid. Please specify it using business, entertainment, general, health, science, sports, or technology"))
}
}
## Check country
if(!is.null(country)){
if(length(country)>1){
stop("You cannot specify more than one country")
}
if(!country %in% c("ae", "ar", "at", "au", "be", "bg", "br", "ca",
"ch", "cn", "co", "cu", "cz", "de", "eg", "fr",
"gb", "gr", "hk", "hu", "id", "ie", "il", "in",
"it", "jp", "kr", "lt", "lv", "ma", "mx", "my",
"ng", "nl", "no", "nz", "ph", "pl", "pt", "ro",
"rs", "ru", "sa", "se", "sg", "si", "sk", "th",
"tr", "tw", "ua", "us", "ve", "za")){
stop(paste(country, 'is not valid. Please specify it using "ae", "ar", "at", "au", "be", "bg", "br", "ca"',
'"ch", "cn", "co", "cu", "cz", "de", "eg", "fr"',
'"gb", "gr", "hk", "hu", "id", "ie", "il", "in"',
'"it", "jp", "kr", "lt", "lv", "ma", "mx", "my"',
'"ng", "nl", "no", "nz", "ph", "pl", "pt", "ro"',
'"rs", "ru", "sa", "se", "sg", "si", "sk", "th"',
'"tr", "tw", "ua", "us", "ve", or "za".',
"See : https://newsapi.org/sources"))
}
}
## Check sources
source_vec <- news_sources(api_key = api_key) %>%
select(id) %>%
pull()
if(!is.null(sources)){
if(length(sources)>1){
stop("You cannot specify more than one country")
}
if(!source %in% source_vec){
stop(paste0(source, "is not valid. Check news_sources(<YOUR API KEY>)"))
}
}
## Check page
if(!is.numeric(page)) {
stop("Page should be a number.")
}
## Check pageSize
if(!is.numeric(pageSize)) {
stop("You need to insert numeric values for the number of texts per page.")
}
else if(pageSize > 100) {
stop("Page size cannot not exceed 100 articles per page.")
}
## Check api_key
if (nchar(api_key) == 0){
stop(paste("You did not correctly specify your API key neither as global",
"variable nor with the function call. See documentation for",
"further info."))
}
# Access NEWS API ----
## Query
query_params <- list(category  = category,
sources   = sources,
country   = country,
q         = keywords,
pageSize  = pageSize,
page      = page)
url <- httr::parse_url(url = "https://newsapi.org/v2/top-headlines")
url$scheme <- "https"
url$query <- query_params
## Data parsed
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = api_key))
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
tidy_data <- parsed %>% pluck(3) %>% tibble::as_tibble()
tot_result <- parsed %>% pluck(2)
# Parsed all page ----
if(get_all){
if(to_result > pageSize){
## Calculate numb. of page left
max_no_of_pages <- ceiling(tot_result / pageSize)
## iterate through all page left
for(i in seq.int(2, max_no_of_pages)) {
## temp. data
query_params <- list(category  = category,
sources   = sources,
country   = country,
q         = keywords,
pageSize  = pageSize,
page      = i)
url <- httr::parse_url(url = "https://newsapi.org/v2/top-headlines")
url$scheme <- "https"
url$query <- query_params
## Data parsed
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = api_key))
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
temp <- parsed %>% pluck(3) %>% tibble::as_tibble()
status_code <- resp %>% pluck(2)
## bind new data
tidy_data <- bind_rows(tidy_data, temp)
# check if last status-code != 200
if (status_code != 200) break
}
}
}
return(tidy_data)
}
news_headlines(category = "business", get_all = TRUE, api_key = api_key)
news_headlines <- function(keywords = NULL,
category = NULL,
country = NULL,
sources = NULL,
page = 1,
pageSize = 100,
get_all = FALSE,
api_key = Sys.getenv("NEWS_API_KEY")){
# error and warning handling ------
## if any arguments NULL
if(all(map_lgl(list(keywords, category, country, sources), is.null))){
stop(paste("Please provide at least keywords, category, country, and source"))
}
## Check if combination sources, country or category allowed
if (!is.null(sources) & (!is.null(country) | !is.null(category))){
stop(paste0("'sources' cannot be used together with ",
"'country' and/or 'category'."))
}
## Check keywords
if(!is.null(keywords)){
if(length(keywords) > 1){
stop("You can only specify one keywords string.")
}
}
## Check category
if(!is.null(category)){
if(length(category) > 1){
stop("You cannot specify more than one category.")
}
if(!category %in% c("business", "entertainment", "general",
"health", "science", "sports", "technology")){
stop(paste(category, "is not valid. Please specify it using business, entertainment, general, health, science, sports, or technology"))
}
}
## Check country
if(!is.null(country)){
if(length(country)>1){
stop("You cannot specify more than one country")
}
if(!country %in% c("ae", "ar", "at", "au", "be", "bg", "br", "ca",
"ch", "cn", "co", "cu", "cz", "de", "eg", "fr",
"gb", "gr", "hk", "hu", "id", "ie", "il", "in",
"it", "jp", "kr", "lt", "lv", "ma", "mx", "my",
"ng", "nl", "no", "nz", "ph", "pl", "pt", "ro",
"rs", "ru", "sa", "se", "sg", "si", "sk", "th",
"tr", "tw", "ua", "us", "ve", "za")){
stop(paste(country, 'is not valid. Please specify it using "ae", "ar", "at", "au", "be", "bg", "br", "ca"',
'"ch", "cn", "co", "cu", "cz", "de", "eg", "fr"',
'"gb", "gr", "hk", "hu", "id", "ie", "il", "in"',
'"it", "jp", "kr", "lt", "lv", "ma", "mx", "my"',
'"ng", "nl", "no", "nz", "ph", "pl", "pt", "ro"',
'"rs", "ru", "sa", "se", "sg", "si", "sk", "th"',
'"tr", "tw", "ua", "us", "ve", or "za".',
"See : https://newsapi.org/sources"))
}
}
## Check sources
source_vec <- news_sources(api_key = api_key) %>%
select(id) %>%
pull()
if(!is.null(sources)){
if(length(sources)>1){
stop("You cannot specify more than one country")
}
if(!source %in% source_vec){
stop(paste0(source, "is not valid. Check news_sources(<YOUR API KEY>)"))
}
}
## Check page
if(!is.numeric(page)) {
stop("Page should be a number.")
}
## Check pageSize
if(!is.numeric(pageSize)) {
stop("You need to insert numeric values for the number of texts per page.")
}
else if(pageSize > 100) {
stop("Page size cannot not exceed 100 articles per page.")
}
## Check api_key
if (nchar(api_key) == 0){
stop(paste("You did not correctly specify your API key neither as global",
"variable nor with the function call. See documentation for",
"further info."))
}
# Access NEWS API ----
## Query
query_params <- list(category  = category,
sources   = sources,
country   = country,
q         = keywords,
pageSize  = pageSize,
page      = page)
url <- httr::parse_url(url = "https://newsapi.org/v2/top-headlines")
url$scheme <- "https"
url$query <- query_params
## Data parsed
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = api_key))
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
tidy_data <- parsed %>% pluck(3) %>% tibble::as_tibble()
tot_result <- parsed %>% pluck(2)
# Parsed all page ----
if(get_all){
if(tot_result > pageSize){
## Calculate numb. of page left
max_no_of_pages <- ceiling(tot_result / pageSize)
## iterate through all page left
for(i in seq.int(2, max_no_of_pages)) {
## temp. data
query_params <- list(category  = category,
sources   = sources,
country   = country,
q         = keywords,
pageSize  = pageSize,
page      = i)
url <- httr::parse_url(url = "https://newsapi.org/v2/top-headlines")
url$scheme <- "https"
url$query <- query_params
## Data parsed
resp <- httr::GET(url, httr::add_headers("X-Api-Key" = api_key))
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
temp <- parsed %>% pluck(3) %>% tibble::as_tibble()
status_code <- resp %>% pluck(2)
## bind new data
tidy_data <- bind_rows(tidy_data, temp)
# check if last status-code != 200
if (status_code != 200) break
}
}
}
return(tidy_data)
}
news_headlines(category = "business", get_all = TRUE, api_key = api_key)
?ggplot2
??ggplot2
??tidyverse
??newsanchor
library(newsR)
news_sources(api_key)
news_headlines(keywords = "jokowi", api_key = api_key)
news_headlines(keywords = "Trump", api_key = api_key)
news_headlines(keywords = "Trump", get_all = TRUE, api_key = api_key)
news_headlines(keywords = "covid19", get_all = TRUE, api_key = api_key)
news_headlines(keywords = "covid19", get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(keywords = "Corona Virus", get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_sources(api_key) %>% View()
news_headlines(country = "id", get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(country = "en", get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(country = "us", get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
news_headlines(keywords = "Apple", get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
?news_headlines
library(newR)
news_api_key()
library(newsR)
news_api_key()
api_key
newsR::news_api_key(tempdir())
newsR::news_api_key(".")
newsR::news_api_key("Global")
library(newR)
news_headlines(country = "id")
library(newsR)
news_headlines(country = "id")
library(newsR)
?file.create
usethis::use_package("askpass")
usethis::use_package("purrr")
usethis::use_package("httr")
usethis::use_package("tibble")
usethis::use_package("jsonlite")
usethis::use_package("dplyr")
usethis::use_package("lubridate")
url <- "https://newsapi.org/v2/everything?q=bitcoin&apiKey=dec7dc7eec124dbfb2adb9034c71b0bd"
resp <- GET(url)
resp <- httr::GET(url)
View(resp)
parsed <- fromJSON(
content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
parsed <- jsonlite::fromJSON(
content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
parsed <- jsonlite::fromJSON(
httr::content(
resp, as = "text", type = "application/json", encoding = "UTF-8"
),
flatten = TRUE
)
View(parsed)
library(newsR)
news_everything(keyword = "jokowi", language = "id", get_all = TRUE)
news_everything(keyword = "jokowi",  get_all = TRUE)
news_everything(keyword = "jokowi",  get_all = TRUE, api_key = "dec7dc7eec124dbfb2adb9034c71b0bd")
usethis::use_github()
usethis::use_github()
